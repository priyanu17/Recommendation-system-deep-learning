{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build shallow and deep recommender models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train, test = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (944 users x 1683 items x 80000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (944 users x 1683 items x 20000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both train and test are Interactions datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "\n",
    "model = ExplicitFactorizationModel( \n",
    "                                  loss='regression',\n",
    "                                   embedding_dim=128,  # latent dimensionality\n",
    "                                   n_iter=10,  # number of epochs of training\n",
    "                                   batch_size=1024,  # minibatch size\n",
    "                                   l2=1e-9,  # strength of L2 regularization\n",
    "                                   learning_rate=1e-3,\n",
    "                                   use_cuda=torch.cuda.is_available()\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 13.102626993686338\n",
      "Epoch 1: loss 7.343984546540659\n",
      "Epoch 2: loss 1.760753965076012\n",
      "Epoch 3: loss 1.0663905166372467\n",
      "Epoch 4: loss 0.9374866161165358\n",
      "Epoch 5: loss 0.8874881184553798\n",
      "Epoch 6: loss 0.8622164001947716\n",
      "Epoch 7: loss 0.844689649871633\n",
      "Epoch 8: loss 0.8269687310049806\n",
      "Epoch 9: loss 0.814429962936836\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "train_rmse = rmse_score(model, train)\n",
    "test_rmse = rmse_score(model, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Root mean squared error is : 0.8882106\n",
      "The Test Root mean squared error is : 0.9452395\n"
     ]
    }
   ],
   "source": [
    "print(\"The Train Root mean squared error is : \" + str(train_rmse))\n",
    "print(\"The Test Root mean squared error is : \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicit Factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train_2, test_2 = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "model_2 = ImplicitFactorizationModel(loss='pointwise',\n",
    "                                       embedding_dim=32,\n",
    "                                       n_iter=10,\n",
    "                                       batch_size=256, \n",
    "                                       l2=0.0, \n",
    "                                       learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.7051847720869814\n",
      "Epoch 1: loss 0.49396898352300017\n",
      "Epoch 2: loss 0.45015634277377264\n",
      "Epoch 3: loss 0.42219457468285726\n",
      "Epoch 4: loss 0.40291141149715876\n",
      "Epoch 5: loss 0.38861463302240584\n",
      "Epoch 6: loss 0.37210562225347893\n",
      "Epoch 7: loss 0.359981769285263\n",
      "Epoch 8: loss 0.3469677418946458\n",
      "Epoch 9: loss 0.3376966994791366\n"
     ]
    }
   ],
   "source": [
    "model_2.fit(train_2, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.477442 , 10.948789 , 14.368172 , ..., -6.5751863, -7.5927672,\n",
       "       -9.1422825], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict( user_ids = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.263647,  13.174006, -15.468727, ..., -10.127995,  -7.677381,\n",
       "        -8.717113], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict( user_ids = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean reciprocal rank \n",
    "from spotlight.evaluation import mrr_score\n",
    "\n",
    "mrr = mrr_score(model_2, test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01358905 0.06459099 0.02376197 0.05453671 0.02463989 0.01652867\n",
      " 0.01618702 0.03447073 0.00508511 0.01835612 0.00827755 0.02134035\n",
      " 0.00915235 0.09351695 0.07196375 0.02005673 0.01659988 0.02774767\n",
      " 0.15434551 0.02008614 0.04317795 0.05720446 0.00984205 0.01590831\n",
      " 0.01577337 0.03938553 0.02091556 0.00914351 0.10471442 0.04615974\n",
      " 0.02636593 0.02006841 0.04617265 0.01599524 0.05130753 0.02792756\n",
      " 0.00854116 0.01135634 0.04146671 0.13709949 0.0467006  0.02977948\n",
      " 0.00834788 0.03124541 0.08706658 0.00999641 0.02592908 0.11596851\n",
      " 0.00979898 0.08743709 0.0220855  0.02729337 0.09623827 0.01731166\n",
      " 0.10293222 0.03293043 0.01058861 0.01672781 0.00941641 0.01776872\n",
      " 0.11148878 0.0124746  0.0438643  0.01734961 0.01391666 0.02563872\n",
      " 0.01885218 0.032784   0.07769622 0.04349517 0.01443981 0.02373638\n",
      " 0.01790698 0.01517111 0.01604054 0.00934572 0.06420635 0.02062058\n",
      " 0.00666129 0.00940779 0.01776626 0.01542079 0.01753664 0.02701173\n",
      " 0.00773667 0.01714286 0.04164801 0.08946923 0.00975567 0.00989233\n",
      " 0.01610893 0.00823657 0.01453141 0.00955593 0.01717051 0.03367566\n",
      " 0.01338219 0.06136227 0.02429768 0.12029949 0.01915783 0.01565259\n",
      " 0.17883742 0.10617683 0.07142857 0.02830834 0.0198754  0.04176975\n",
      " 0.02918434 0.02552124 0.0877193  0.02866242 0.02706756 0.0200122\n",
      " 0.01999905 0.02840665 0.02709802 0.01845826 0.04482637 0.05465058\n",
      " 0.01241846 0.03091252 0.0408319  0.11713336 0.00674672 0.07525849\n",
      " 0.09342345 0.01246895 0.02663185 0.01757444 0.01379781 0.04553413\n",
      " 0.04328814 0.15151574 0.01947485 0.0525746  0.01059045 0.01280078\n",
      " 0.02907862 0.05408118 0.06248475 0.01454071 0.1687037  0.01017441\n",
      " 0.0159322  0.02773512 0.03225806 0.02481125 0.12736508 0.02582337\n",
      " 0.02413369 0.02032962 0.05934912 0.07487217 0.04378623 0.00718919\n",
      " 0.02337857 0.03497293 0.06388076 0.01715658 0.03748119 0.02696029\n",
      " 0.08305013 0.01860011 0.11615733 0.05314967 0.00367332 0.05630961\n",
      " 0.01291684 0.03166498 0.05041469 0.3366146  0.06074268 0.01001972\n",
      " 0.06223048 0.05318376 0.01867553 0.01524808 0.05555305 0.01447341\n",
      " 0.00959194 0.04513776 0.08407024 0.01343562 0.0306424  0.01775616\n",
      " 0.03737626 0.03136558 0.0111385  0.10625934 0.03834572 0.02348742\n",
      " 0.05578123 0.00960113 0.00839868 0.01324105 0.0295013  0.01830346\n",
      " 0.09407013 0.02040941 0.01565457 0.0282488  0.15007057 0.0714647\n",
      " 0.06073403 0.03860845 0.03083    0.01812191 0.02174749 0.01332872\n",
      " 0.01360445 0.01785331 0.01033619 0.01312442 0.03685134 0.01544418\n",
      " 0.01619074 0.00980943 0.00512572 0.07417582 0.01224612 0.01985171\n",
      " 0.0439078  0.00731773 0.00768616 0.01171157 0.02559745 0.05279651\n",
      " 0.0501761  0.0086585  0.04109108 0.02222878 0.03689082 0.01049026\n",
      " 0.01398673 0.02185258 0.01550781 0.03046602 0.02296444 0.01630114\n",
      " 0.04047619 0.00266974 0.01152352 0.01699551 0.0159675  0.01289236\n",
      " 0.06208628 0.02498593 0.02651184 0.0153867  0.02233736 0.02822178\n",
      " 0.01731186 0.01431717 0.01965336 0.01610088 0.02910853 0.05984978\n",
      " 0.01912668 0.02525129 0.07625764 0.02816049 0.00997276 0.01838028\n",
      " 0.05298116 0.05026091 0.01064089 0.02697352 0.01286755 0.01146551\n",
      " 0.01113409 0.02698257 0.09646353 0.05939429 0.01913021 0.00690953\n",
      " 0.12610298 0.00684932 0.00723989 0.01859663 0.05616392 0.02077441\n",
      " 0.01019927 0.02440713 0.09192785 0.01878279 0.02386145 0.09304854\n",
      " 0.08363527 0.02746984 0.01190359 0.03705602 0.01477254 0.04777147\n",
      " 0.01541997 0.02103059 0.01740268 0.03541491 0.00523245 0.01914551\n",
      " 0.00872582 0.22734454 0.00903364 0.31889403 0.02947441 0.29308555\n",
      " 0.02228808 0.0267796  0.07437862 0.01349464 0.01844536 0.02012184\n",
      " 0.00859887 0.02467255 0.05080083 0.08373908 0.06317702 0.04364585\n",
      " 0.02996612 0.01369776 0.01246985 0.01609033 0.03816791 0.02291277\n",
      " 0.01194789 0.01235108 0.02836511 0.01640057 0.01593121 0.0611311\n",
      " 0.00551819 0.03967209 0.02696262 0.00838056 0.04761905 0.01142331\n",
      " 0.06081255 0.02053047 0.03526233 0.00700947 0.05411393 0.04611714\n",
      " 0.02943862 0.01413061 0.02119192 0.01545299 0.03401119 0.01347955\n",
      " 0.07170573 0.02564755 0.16254263 0.05774225 0.06728111 0.0164914\n",
      " 0.08184524 0.05275901 0.01951215 0.0120119  0.01046691 0.05016054\n",
      " 0.01746091 0.06078517 0.0131934  0.02174529 0.00862648 0.06266441\n",
      " 0.06154434 0.01272636 0.0101112  0.01073377 0.04914824 0.06787865\n",
      " 0.02793384 0.00882019 0.07457698 0.04018221 0.02994126 0.00837606\n",
      " 0.01453021 0.01127711 0.00552096 0.03585136 0.01767506 0.34759241\n",
      " 0.02262965 0.0536075  0.00901876 0.01375097 0.02410148 0.05476093\n",
      " 0.02701148 0.00601752 0.00885898 0.01724951 0.01511056 0.06034354\n",
      " 0.06768129 0.02721864 0.0089067  0.1628647  0.04014087 0.07112269\n",
      " 0.02377853 0.05817303 0.00372349 0.01140215 0.01166157 0.05192939\n",
      " 0.03335684 0.16806925 0.04715364 0.03742956 0.07284211 0.08615819\n",
      " 0.00695662 0.01209817 0.02084167 0.04977422 0.05030576 0.01403114\n",
      " 0.01439142 0.01804679 0.04379944 0.04650159 0.01163244 0.04728406\n",
      " 0.01622276 0.11882368 0.01310463 0.02026263 0.20989449 0.02318272\n",
      " 0.02013674 0.01669344 0.01135592 0.00849152 0.01165459 0.04326321\n",
      " 0.01547365 0.04752299 0.09887068 0.05604895 0.03824364 0.06533754\n",
      " 0.00908032 0.06324522 0.01197148 0.01879855 0.08615978 0.0074815\n",
      " 0.02429424 0.02743922 0.00887609 0.02946611 0.02768997 0.01798833\n",
      " 0.00966218 0.03841157 0.00979905 0.05074606 0.0280796  0.03800741\n",
      " 0.00628345 0.17318115 0.03338902 0.05475145 0.19920776 0.01695382\n",
      " 0.01033718 0.04596585 0.00604524 0.02919801 0.23024995 0.03614924\n",
      " 0.07922065 0.06751496 0.02040628 0.07007652 0.02146942 0.02400851\n",
      " 0.12179261 0.1942166  0.05760671 0.01697533 0.02245123 0.03961489\n",
      " 0.02962015 0.01705275 0.02285648 0.13371709 0.08574009 0.01999425\n",
      " 0.01254723 0.09189513 0.04321335 0.01241623 0.0176634  0.02067376\n",
      " 0.01955591 0.00812051 0.05086209 0.07296776 0.01848776 0.01437207\n",
      " 0.00859154 0.01139975 0.0941687  0.01819748 0.02174151 0.06703739\n",
      " 0.03722658 0.04698863 0.1190404  0.02155926 0.17726635 0.02288472\n",
      " 0.01655007 0.01574292 0.01248654 0.02264774 0.05009735 0.02111719\n",
      " 0.00993855 0.02452251 0.12394849 0.04206465 0.01711645 0.13051416\n",
      " 0.19450065 0.01540742 0.03212238 0.00937111 0.01314376 0.01837365\n",
      " 0.01128042 0.02112048 0.01123869 0.04836126 0.12926201 0.11321051\n",
      " 0.01835078 0.05570419 0.01315656 0.02784836 0.01001101 0.0422956\n",
      " 0.03588517 0.03116575 0.0450593  0.04643966 0.03088731 0.09395816\n",
      " 0.01462335 0.05132171 0.01762104 0.06919382 0.11824409 0.00646665\n",
      " 0.01701245 0.01341944 0.0183606  0.01006814 0.14071352 0.06769495\n",
      " 0.01722172 0.01106421 0.0110657  0.0221429  0.11388203 0.03532155\n",
      " 0.01498268 0.02219862 0.02094197 0.11849051 0.04303001 0.00982481\n",
      " 0.02672423 0.01296296 0.08828586 0.07620365 0.01548175 0.10672544\n",
      " 0.13199035 0.01383858 0.0089099  0.01683536 0.0460515  0.0127124\n",
      " 0.13799058 0.02936892 0.00908531 0.009279   0.01031403 0.05619722\n",
      " 0.01826376 0.01726871 0.02382043 0.30438312 0.01733672 0.03069096\n",
      " 0.03430759 0.01514959 0.03916052 0.04854354 0.04037346 0.01390648\n",
      " 0.0174679  0.05345307 0.00669185 0.01846895 0.11585122 0.03292327\n",
      " 0.02075786 0.00913405 0.03159373 0.03005805 0.00634305 0.03904639\n",
      " 0.08441357 0.0148166  0.00790963 0.01117456 0.00772572 0.02589709\n",
      " 0.05659241 0.08073431 0.05250788 0.08730391 0.01221906 0.01294686\n",
      " 0.01698514 0.01982778 0.03732532 0.01719468 0.0294303  0.06651506\n",
      " 0.0166261  0.02848958 0.02179363 0.01054936 0.00968502 0.0100918\n",
      " 0.01101365 0.01930962 0.04815971 0.03214957 0.04677416 0.01518223\n",
      " 0.04646803 0.00907788 0.03570676 0.09431906 0.01117041 0.01805966\n",
      " 0.01012183 0.02272897 0.05257428 0.02271011 0.00817624 0.01795443\n",
      " 0.01802657 0.0147034  0.04494297 0.02396707 0.02196732 0.03138625\n",
      " 0.00905385 0.11088747 0.01472867 0.0170653  0.01617875 0.11218042\n",
      " 0.23443223 0.01653338 0.00515787 0.02964395 0.08732049 0.09398277\n",
      " 0.0246718  0.00812438 0.10915564 0.01092883 0.01976114 0.02088638\n",
      " 0.02555069 0.02590232 0.24948646 0.03271294 0.04313248 0.03378675\n",
      " 0.02037818 0.01591887 0.01854704 0.01689796 0.02768852 0.02285182\n",
      " 0.02537089 0.04951712 0.02012528 0.00826986 0.02214688 0.00941008\n",
      " 0.11664229 0.01264582 0.02929857 0.02674208 0.02921153 0.00911167\n",
      " 0.01823315 0.01234056 0.01658488 0.02336767 0.02775695 0.03294143\n",
      " 0.00693195 0.01893194 0.05282574 0.02849638 0.098278   0.0275232\n",
      " 0.05171684 0.15644303 0.19863896 0.05705401 0.06017302 0.01799264\n",
      " 0.00900579 0.02170097 0.09463441 0.01428612 0.02654249 0.05882353\n",
      " 0.01330569 0.04712123 0.02280186 0.01343308 0.10037667 0.02448636\n",
      " 0.03030113 0.09809942 0.01970106 0.02934433 0.03229471 0.02114848\n",
      " 0.01445126 0.03321997 0.01258633 0.01700425 0.01342519 0.03101722\n",
      " 0.00876747 0.01760904 0.03331157 0.02421001 0.0900807  0.01411846\n",
      " 0.00873024 0.02320271 0.03907266 0.0063122  0.02868903 0.04196267\n",
      " 0.01789767 0.04663398 0.1443826  0.03588159 0.01533623 0.01564679\n",
      " 0.02358752 0.03640074 0.01130692 0.04491603 0.01307033 0.02508108\n",
      " 0.05980826 0.02159486 0.03149859 0.09741051 0.05245464 0.02231765\n",
      " 0.0309524  0.0070269  0.23706584 0.1643134  0.12111775 0.01160377\n",
      " 0.05707986 0.01244196 0.02930258 0.01871534 0.06216415 0.01009147\n",
      " 0.06719839 0.0531108  0.04509693 0.00703199 0.01276165 0.0144886\n",
      " 0.01773483 0.01677719 0.07238873 0.13337428 0.020911   0.03068463\n",
      " 0.0066999  0.02424825 0.02269251 0.14015152 0.04855096 0.04621633\n",
      " 0.16244552 0.06576389 0.01470621 0.0420111  0.01142738 0.12440958\n",
      " 0.09845666 0.0080267  0.20565663 0.04846154 0.02933945 0.01128414\n",
      " 0.04210194 0.045576   0.04028584 0.02300188 0.19627363 0.01372168\n",
      " 0.04091622 0.03030864 0.01998998 0.06693965 0.01908132 0.05203232\n",
      " 0.03351051 0.09996625 0.11657503 0.04399064 0.01070109 0.0187042\n",
      " 0.09909969 0.03017198 0.01602717 0.07556458 0.0482945  0.00988899\n",
      " 0.04759395 0.01157793 0.08111211 0.04123592 0.01068577 0.01209619\n",
      " 0.06085028 0.02989008 0.01825693 0.03173077 0.00719155 0.03074462\n",
      " 0.01246067 0.0139773  0.00790887 0.0561713  0.03996762 0.00966598\n",
      " 0.01469499 0.05928272 0.021664   0.01488001 0.02750195 0.01014106\n",
      " 0.02535838 0.05213225 0.01265823 0.03190212 0.03667292 0.25578308\n",
      " 0.01088485 0.01505697 0.03448276 0.01370272 0.01714854 0.04166433\n",
      " 0.02894261 0.03441039 0.013537   0.02779896 0.01637419 0.21162147\n",
      " 0.01241199 0.02058823 0.03114587 0.02534747 0.04254337 0.02428427\n",
      " 0.02550935 0.01420164 0.0257176  0.0867674  0.06587492 0.01466181\n",
      " 0.0292951  0.01372354 0.02229089 0.01886826 0.07122174 0.02461898\n",
      " 0.01128889 0.00868803 0.01560906 0.04120339 0.01845018 0.0208093\n",
      " 0.01990753 0.00634459 0.22967172 0.0158089  0.04340831 0.01109123\n",
      " 0.03600672 0.05117822 0.01929636 0.01728976 0.03433455 0.02792437\n",
      " 0.03526711 0.02227906 0.01054833 0.02990047 0.01144623 0.01829256\n",
      " 0.03207696 0.038667   0.04240274 0.00626913 0.04210256 0.04604429\n",
      " 0.06210588 0.04871173 0.01454312 0.01976767 0.35446325 0.04119659\n",
      " 0.01599512]\n"
     ]
    }
   ],
   "source": [
    "# numpy array of shape num_users:\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import precision_recall_score\n",
    "\n",
    "prs = precision_recall_score(model_2, test_2, k  = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision recall score is : (array([0.2, 0.3, 0. , 0.1, 0.2, 0.1, 0.2, 0.1, 0. , 0.1, 0. , 0.1, 0.3,\n",
      "       0.1, 0.1, 0.1, 0. , 0.4, 0.1, 0. , 0.3, 0.1, 0. , 0. , 0. , 0.2,\n",
      "       0. , 0. , 0.1, 0.1, 0. , 0. , 0.1, 0. , 0.2, 0. , 0. , 0. , 0. ,\n",
      "       0.2, 0.2, 0.2, 0. , 0.3, 0.2, 0. , 0. , 0.2, 0.1, 0.2, 0. , 0.1,\n",
      "       0.1, 0. , 0.1, 0.3, 0. , 0.1, 0.1, 0.2, 0.4, 0. , 0.2, 0.1, 0. ,\n",
      "       0. , 0. , 0. , 0.1, 0.1, 0. , 0.2, 0.1, 0. , 0. , 0. , 0.3, 0. ,\n",
      "       0. , 0. , 0. , 0.1, 0.1, 0. , 0. , 0. , 0.2, 0.1, 0. , 0.1, 0. ,\n",
      "       0. , 0. , 0. , 0.2, 0.1, 0. , 0.1, 0.1, 0.1, 0. , 0.2, 0.2, 0.4,\n",
      "       0.1, 0.1, 0. , 0.1, 0.1, 0.1, 0.1, 0. , 0. , 0. , 0.2, 0.2, 0.1,\n",
      "       0.1, 0.2, 0.1, 0. , 0.1, 0.2, 0.1, 0. , 0.2, 0.2, 0.1, 0. , 0.5,\n",
      "       0. , 0.1, 0.1, 0.1, 0. , 0.3, 0. , 0. , 0.1, 0.1, 0.1, 0. , 0.2,\n",
      "       0. , 0.2, 0. , 0. , 0.2, 0.1, 0. , 0.3, 0.1, 0.1, 0.2, 0. , 0. ,\n",
      "       0. , 0.3, 0.3, 0.1, 0.2, 0.1, 0.2, 0. , 0.1, 0.1, 0. , 0.3, 0. ,\n",
      "       0. , 0.2, 0.1, 0.1, 0.1, 0.1, 0.3, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1,\n",
      "       0.2, 0.1, 0.2, 0.1, 0.1, 0.2, 0. , 0.4, 0. , 0. , 0.1, 0.1, 0.1,\n",
      "       0. , 0.3, 0.1, 0.1, 0.2, 0.2, 0. , 0.3, 0.3, 0.1, 0.1, 0.1, 0. ,\n",
      "       0. , 0.1, 0. , 0. , 0. , 0. , 0.1, 0.1, 0. , 0. , 0. , 0. , 0.1,\n",
      "       0.1, 0.3, 0. , 0. , 0. , 0. , 0.1, 0.2, 0. , 0. , 0.1, 0.3, 0.2,\n",
      "       0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0.2, 0. , 0.1, 0.2,\n",
      "       0. , 0.3, 0. , 0.1, 0. , 0.2, 0. , 0. , 0.3, 0.1, 0.1, 0. , 0. ,\n",
      "       0.1, 0.1, 0. , 0.1, 0.1, 0.1, 0. , 0.2, 0.2, 0.1, 0.2, 0. , 0.2,\n",
      "       0.2, 0. , 0. , 0.3, 0. , 0.1, 0.1, 0.1, 0. , 0. , 0. , 0.2, 0.2,\n",
      "       0. , 0.2, 0.1, 0.3, 0.2, 0.2, 0.3, 0.4, 0.2, 0. , 0.1, 0.3, 0. ,\n",
      "       0. , 0. , 0.1, 0.1, 0.2, 0.3, 0.2, 0.1, 0.3, 0.1, 0. , 0.1, 0.1,\n",
      "       0. , 0.2, 0.2, 0.1, 0.1, 0.2, 0. , 0.1, 0. , 0. , 0.3, 0.1, 0. ,\n",
      "       0.1, 0.2, 0.1, 0.1, 0.3, 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0.1,\n",
      "       0.3, 0. , 0.1, 0.3, 0.2, 0.1, 0.1, 0.2, 0.3, 0. , 0.3, 0. , 0.1,\n",
      "       0.2, 0.1, 0.2, 0.1, 0.1, 0. , 0. , 0. , 0.3, 0.1, 0.1, 0.2, 0. ,\n",
      "       0. , 0.1, 0.1, 0. , 0. , 0. , 0.1, 0.1, 0.3, 0. , 0.1, 0.1, 0.1,\n",
      "       0. , 0.1, 0.1, 0. , 0.2, 0. , 0.3, 0.2, 0.1, 0. , 0. , 0.2, 0.2,\n",
      "       0.2, 0. , 0.1, 0.1, 0.1, 0.2, 0.4, 0.1, 0.1, 0.4, 0.2, 0.3, 0. ,\n",
      "       0.2, 0. , 0.1, 0. , 0.1, 0.1, 0.1, 0.3, 0.1, 0.2, 0.1, 0. , 0.1,\n",
      "       0.1, 0. , 0.1, 0. , 0. , 0.1, 0.2, 0.1, 0. , 0.3, 0. , 0.3, 0.1,\n",
      "       0.1, 0.5, 0.1, 0. , 0. , 0.2, 0.1, 0.2, 0.1, 0. , 0.2, 0.2, 0.3,\n",
      "       0.1, 0.1, 0. , 0.1, 0. , 0. , 0.1, 0.2, 0. , 0.2, 0. , 0.4, 0.2,\n",
      "       0.1, 0. , 0.1, 0. , 0.1, 0. , 0.1, 0. , 0.3, 0.2, 0.3, 0.2, 0.1,\n",
      "       0. , 0.2, 0. , 0.4, 0.2, 0.5, 0.2, 0.1, 0. , 0.2, 0.1, 0.1, 0.1,\n",
      "       0.3, 0.1, 0. , 0. , 0.2, 0.4, 0.1, 0. , 0.1, 0.1, 0. , 0.1, 0.1,\n",
      "       0.2, 0.1, 0.3, 0.2, 0.1, 0. , 0.2, 0.2, 0.1, 0.2, 0. , 0.1, 0.2,\n",
      "       0. , 0. , 0.3, 0. , 0.1, 0.1, 0.1, 0.2, 0. , 0. , 0. , 0. , 0. ,\n",
      "       0.2, 0. , 0. , 0.1, 0.1, 0.1, 0.1, 0.2, 0.3, 0. , 0. , 0. , 0.1,\n",
      "       0. , 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0. , 0. , 0.2,\n",
      "       0. , 0.3, 0.1, 0.1, 0.3, 0.1, 0. , 0.4, 0. , 0.1, 0.1, 0. , 0. ,\n",
      "       0. , 0.1, 0. , 0.1, 0.3, 0. , 0. , 0. , 0. , 0.4, 0. , 0. , 0. ,\n",
      "       0. , 0.1, 0.1, 0. , 0.2, 0. , 0.1, 0.1, 0. , 0.2, 0.1, 0. , 0. ,\n",
      "       0.1, 0.1, 0.2, 0.1, 0.1, 0. , 0.1, 0. , 0.1, 0. , 0. , 0.1, 0.2,\n",
      "       0. , 0.3, 0.1, 0. , 0.1, 0.2, 0.1, 0.2, 0. , 0.1, 0. , 0. , 0.1,\n",
      "       0. , 0. , 0. , 0.2, 0. , 0. , 0.3, 0.3, 0.1, 0. , 0.1, 0. , 0.1,\n",
      "       0.2, 0.1, 0.2, 0.1, 0.1, 0. , 0. , 0.1, 0.1, 0.1, 0. , 0.2, 0. ,\n",
      "       0. , 0.2, 0. , 0. , 0.1, 0. , 0. , 0.2, 0. , 0.2, 0.2, 0.1, 0.1,\n",
      "       0. , 0.2, 0.1, 0. , 0.2, 0. , 0.2, 0.1, 0. , 0.2, 0. , 0. , 0.2,\n",
      "       0.1, 0.1, 0.1, 0. , 0.2, 0. , 0. , 0. , 0.2, 0.3, 0. , 0. , 0.2,\n",
      "       0.2, 0.1, 0.1, 0. , 0.1, 0.2, 0. , 0.1, 0. , 0.2, 0.3, 0. , 0.1,\n",
      "       0.1, 0. , 0. , 0.1, 0.1, 0. , 0. , 0.2, 0.2, 0.2, 0. , 0. , 0. ,\n",
      "       0.1, 0. , 0.3, 0. , 0.2, 0. , 0.1, 0. , 0.1, 0.2, 0. , 0. , 0. ,\n",
      "       0.1, 0.4, 0. , 0.2, 0. , 0.3, 0.1, 0.2, 0.4, 0.1, 0. , 0.1, 0. ,\n",
      "       0.2, 0. , 0.2, 0. , 0. , 0.1, 0. , 0. , 0.1, 0.1, 0. , 0.1, 0.1,\n",
      "       0. , 0.1, 0. , 0. , 0.2, 0.1, 0. , 0.1, 0. , 0. , 0. , 0.2, 0.1,\n",
      "       0.1, 0.1, 0. , 0.2, 0.2, 0. , 0.1, 0.1, 0.1, 0.2, 0.4, 0.4, 0. ,\n",
      "       0. , 0. , 0.1, 0. , 0. , 0.1, 0.3, 0.1, 0.2, 0. , 0.3, 0.2, 0.1,\n",
      "       0. , 0. , 0.1, 0.2, 0.1, 0. , 0.1, 0.1, 0.1, 0.2, 0.1, 0. , 0.2,\n",
      "       0.1, 0.1, 0. , 0. , 0.3, 0. , 0. , 0.2, 0.3, 0. , 0.3, 0. , 0.2,\n",
      "       0.2, 0.1, 0. , 0. , 0.1, 0.1, 0. , 0.2, 0. , 0.1, 0.2, 0. , 0.2,\n",
      "       0. , 0.2, 0. , 0.1, 0.1, 0.2, 0.1, 0.4, 0. , 0.1, 0.2, 0. , 0.1,\n",
      "       0.3, 0.2, 0.1, 0.2, 0.2, 0.2, 0. , 0.1, 0.2, 0. , 0.1, 0.4, 0.1,\n",
      "       0.2, 0.1, 0.1, 0.1, 0.2, 0.1, 0. , 0.2, 0.4, 0. , 0. , 0. , 0. ,\n",
      "       0. , 0. , 0. , 0.3, 0.3, 0. , 0. , 0.1, 0. , 0.1, 0. , 0. , 0.2,\n",
      "       0.2, 0. , 0. , 0.1, 0.1, 0. , 0.1, 0. , 0.2, 0.2, 0.3, 0.3, 0.1,\n",
      "       0. , 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.3, 0.2, 0.3, 0. , 0.2, 0.1,\n",
      "       0.1, 0.3, 0. , 0.2, 0. , 0.2, 0. , 0.2, 0. , 0. , 0. , 0. , 0.1,\n",
      "       0.1, 0.1, 0. , 0. , 0.1, 0.1, 0.1, 0. , 0.4, 0.1, 0.1, 0.1, 0.2,\n",
      "       0.1, 0.1, 0. , 0. , 0.1, 0. , 0.1, 0.1, 0.5, 0.2, 0. , 0.1, 0.1,\n",
      "       0.2, 0.3, 0. , 0.1, 0.1, 0.2, 0.1]), array([0.03773585, 0.21428571, 0.        , 0.25      , 0.0625    ,\n",
      "       0.02380952, 0.02985075, 0.09090909, 0.        , 0.02702703,\n",
      "       0.        , 0.06666667, 0.02479339, 0.08333333, 0.05263158,\n",
      "       0.04545455, 0.        , 0.06779661, 0.25      , 0.        ,\n",
      "       0.07894737, 0.04545455, 0.        , 0.        , 0.        ,\n",
      "       0.125     , 0.        , 0.        , 0.16666667, 0.07692308,\n",
      "       0.        , 0.        , 0.2       , 0.        , 0.25      ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.28571429,\n",
      "       0.2       , 0.05128205, 0.        , 0.08333333, 0.18181818,\n",
      "       0.        , 0.        , 0.16666667, 0.02222222, 0.28571429,\n",
      "       0.        , 0.08333333, 0.25      , 0.        , 0.25      ,\n",
      "       0.07142857, 0.        , 0.03571429, 0.01612903, 0.04545455,\n",
      "       0.57142857, 0.        , 0.1       , 0.02272727, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.05882353, 0.03225806,\n",
      "       0.        , 0.07142857, 0.05882353, 0.        , 0.        ,\n",
      "       0.        , 0.21428571, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.03333333, 0.02857143, 0.        , 0.        ,\n",
      "       0.        , 0.04761905, 0.2       , 0.        , 0.01587302,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
      "       0.07692308, 0.        , 0.33333333, 0.03571429, 0.2       ,\n",
      "       0.        , 0.04347826, 0.28571429, 0.17391304, 0.33333333,\n",
      "       0.07142857, 0.        , 0.2       , 0.01818182, 0.04347826,\n",
      "       0.5       , 0.        , 0.        , 0.        , 0.11764706,\n",
      "       0.08333333, 0.07142857, 0.0625    , 0.05128205, 0.33333333,\n",
      "       0.        , 0.07692308, 0.15384615, 0.2       , 0.        ,\n",
      "       0.25      , 0.5       , 0.02631579, 0.        , 0.05434783,\n",
      "       0.        , 0.16666667, 0.14285714, 0.25      , 0.        ,\n",
      "       0.3       , 0.        , 0.        , 0.25      , 0.16666667,\n",
      "       0.04761905, 0.        , 0.4       , 0.        , 0.03225806,\n",
      "       0.        , 0.        , 0.11764706, 0.11111111, 0.        ,\n",
      "       0.04615385, 0.04347826, 0.14285714, 0.2       , 0.        ,\n",
      "       0.        , 0.        , 0.1       , 0.09375   , 0.04166667,\n",
      "       0.125     , 0.2       , 0.28571429, 0.        , 0.33333333,\n",
      "       0.14285714, 0.        , 0.2       , 0.        , 0.        ,\n",
      "       0.28571429, 0.33333333, 0.11111111, 0.02439024, 0.125     ,\n",
      "       0.3       , 0.03225806, 0.025     , 0.18181818, 0.06666667,\n",
      "       0.0125    , 0.16666667, 0.2       , 0.01785714, 0.2       ,\n",
      "       0.0625    , 0.11111111, 0.14285714, 0.        , 0.22222222,\n",
      "       0.        , 0.        , 0.04166667, 0.01694915, 0.03846154,\n",
      "       0.        , 0.13636364, 0.02941176, 0.125     , 0.04255319,\n",
      "       0.02777778, 0.        , 0.27272727, 0.375     , 0.2       ,\n",
      "       0.09090909, 0.02272727, 0.        , 0.        , 0.03225806,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.08333333,\n",
      "       0.05263158, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03333333, 0.01234568, 0.16666667, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.2       , 0.33333333, 0.        ,\n",
      "       0.        , 0.04347826, 0.09677419, 0.01886792, 0.        ,\n",
      "       0.05      , 0.        , 0.        , 0.02173913, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.05128205, 0.        ,\n",
      "       0.02380952, 0.4       , 0.        , 0.08823529, 0.        ,\n",
      "       0.0625    , 0.        , 0.08695652, 0.        , 0.        ,\n",
      "       0.06122449, 0.1       , 0.2       , 0.        , 0.        ,\n",
      "       0.16666667, 0.04      , 0.        , 0.04347826, 0.1       ,\n",
      "       0.2       , 0.        , 0.03333333, 0.03571429, 0.03125   ,\n",
      "       0.03636364, 0.        , 0.33333333, 0.0952381 , 0.        ,\n",
      "       0.        , 0.27272727, 0.        , 0.01030928, 0.01754386,\n",
      "       0.33333333, 0.        , 0.        , 0.        , 0.4       ,\n",
      "       0.03571429, 0.        , 0.1       , 0.33333333, 0.07317073,\n",
      "       0.03333333, 0.07407407, 0.04347826, 0.10526316, 0.03773585,\n",
      "       0.        , 0.03030303, 0.13636364, 0.        , 0.        ,\n",
      "       0.        , 0.2       , 0.01052632, 0.4       , 0.06521739,\n",
      "       0.5       , 0.03846154, 0.03658537, 0.25      , 0.        ,\n",
      "       0.01923077, 0.03225806, 0.        , 0.04444444, 0.11111111,\n",
      "       0.07692308, 0.16666667, 0.05714286, 0.        , 0.04166667,\n",
      "       0.        , 0.        , 0.13043478, 0.07142857, 0.        ,\n",
      "       0.02380952, 0.03389831, 0.01754386, 0.08333333, 0.09090909,\n",
      "       0.        , 0.04545455, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.25      , 0.06666667, 0.05769231, 0.        ,\n",
      "       0.25      , 0.075     , 0.04444444, 0.03125   , 0.03030303,\n",
      "       0.04347826, 0.06521739, 0.        , 0.2       , 0.        ,\n",
      "       0.14285714, 0.28571429, 0.16666667, 0.04255319, 0.25      ,\n",
      "       0.33333333, 0.        , 0.        , 0.        , 0.13636364,\n",
      "       0.03846154, 0.14285714, 0.03636364, 0.        , 0.        ,\n",
      "       0.14285714, 0.1       , 0.        , 0.        , 0.        ,\n",
      "       0.09090909, 0.0625    , 0.05      , 0.        , 0.16666667,\n",
      "       0.25      , 0.11111111, 0.        , 0.0212766 , 0.02564103,\n",
      "       0.        , 0.18181818, 0.        , 0.6       , 0.04255319,\n",
      "       0.25      , 0.        , 0.        , 0.03773585, 0.4       ,\n",
      "       0.07692308, 0.        , 0.01052632, 0.02941176, 0.07142857,\n",
      "       0.22222222, 0.16666667, 0.025     , 0.015625  , 0.5       ,\n",
      "       0.07142857, 0.21428571, 0.        , 0.2       , 0.        ,\n",
      "       0.01492537, 0.        , 0.25      , 0.02439024, 0.25      ,\n",
      "       0.15      , 0.09090909, 0.25      , 0.33333333, 0.        ,\n",
      "       0.00980392, 0.01351351, 0.        , 0.16666667, 0.        ,\n",
      "       0.        , 0.04166667, 0.18181818, 0.16666667, 0.        ,\n",
      "       0.10344828, 0.        , 0.3       , 0.01204819, 0.07692308,\n",
      "       0.83333333, 0.05882353, 0.        , 0.        , 0.02985075,\n",
      "       0.03333333, 0.03636364, 0.14285714, 0.        , 0.14285714,\n",
      "       0.33333333, 0.09375   , 0.2       , 0.2       , 0.        ,\n",
      "       0.2       , 0.        , 0.        , 0.07142857, 0.01904762,\n",
      "       0.        , 0.04651163, 0.        , 0.07692308, 0.05263158,\n",
      "       0.02777778, 0.        , 0.02857143, 0.        , 0.11111111,\n",
      "       0.        , 0.11111111, 0.        , 0.33333333, 0.11764706,\n",
      "       0.1       , 0.28571429, 0.03125   , 0.        , 0.11764706,\n",
      "       0.        , 0.09090909, 0.4       , 0.07142857, 0.33333333,\n",
      "       0.05882353, 0.        , 0.10526316, 0.02777778, 0.06666667,\n",
      "       0.11111111, 0.375     , 0.16666667, 0.        , 0.        ,\n",
      "       0.04761905, 0.06349206, 0.03703704, 0.        , 0.11111111,\n",
      "       0.33333333, 0.        , 0.03333333, 0.16666667, 0.05882353,\n",
      "       0.03703704, 0.05454545, 0.05128205, 0.04761905, 0.        ,\n",
      "       0.125     , 0.25      , 0.03225806, 0.04      , 0.        ,\n",
      "       0.02272727, 0.1       , 0.        , 0.        , 0.3       ,\n",
      "       0.        , 0.25      , 0.16666667, 0.02439024, 0.4       ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.07692308, 0.        , 0.        , 0.01754386, 0.1       ,\n",
      "       0.07142857, 0.03703704, 0.18181818, 0.33333333, 0.        ,\n",
      "       0.        , 0.        , 0.02040816, 0.        , 0.02222222,\n",
      "       0.03030303, 0.02083333, 0.16666667, 0.125     , 0.1       ,\n",
      "       0.03846154, 0.03846154, 0.025     , 0.        , 0.        ,\n",
      "       0.15384615, 0.        , 0.09090909, 0.16666667, 0.1       ,\n",
      "       0.04477612, 0.06666667, 0.        , 0.18181818, 0.        ,\n",
      "       0.11111111, 0.11111111, 0.        , 0.        , 0.        ,\n",
      "       0.01694915, 0.        , 0.11111111, 0.375     , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.21052632, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.1       , 0.25      ,\n",
      "       0.        , 0.05405405, 0.        , 0.07692308, 0.14285714,\n",
      "       0.        , 0.16666667, 0.25      , 0.        , 0.        ,\n",
      "       0.02564103, 0.06666667, 0.03773585, 0.11111111, 0.0625    ,\n",
      "       0.        , 0.01351351, 0.        , 0.25      , 0.        ,\n",
      "       0.        , 0.11111111, 0.5       , 0.        , 0.14285714,\n",
      "       0.03448276, 0.        , 0.09090909, 0.28571429, 0.11111111,\n",
      "       0.04      , 0.        , 0.04545455, 0.        , 0.        ,\n",
      "       0.09090909, 0.        , 0.        , 0.        , 0.09090909,\n",
      "       0.        , 0.        , 0.0625    , 0.17647059, 0.05555556,\n",
      "       0.        , 0.02380952, 0.        , 0.04      , 0.08333333,\n",
      "       0.16666667, 0.06060606, 0.33333333, 0.03846154, 0.        ,\n",
      "       0.        , 0.04545455, 0.08333333, 0.03448276, 0.        ,\n",
      "       0.4       , 0.        , 0.        , 0.06896552, 0.        ,\n",
      "       0.        , 0.02      , 0.        , 0.        , 0.10526316,\n",
      "       0.        , 0.16666667, 0.03174603, 0.14285714, 0.01234568,\n",
      "       0.        , 0.22222222, 0.01587302, 0.        , 0.01587302,\n",
      "       0.        , 0.4       , 0.05555556, 0.        , 0.03921569,\n",
      "       0.        , 0.        , 0.07692308, 0.02702703, 0.03125   ,\n",
      "       0.01923077, 0.        , 0.28571429, 0.        , 0.        ,\n",
      "       0.        , 0.18181818, 0.42857143, 0.        , 0.        ,\n",
      "       0.15384615, 0.125     , 0.2       , 0.1       , 0.        ,\n",
      "       0.2       , 0.02631579, 0.        , 0.05882353, 0.        ,\n",
      "       0.125     , 0.5       , 0.        , 0.14285714, 0.04761905,\n",
      "       0.        , 0.        , 0.04      , 0.03703704, 0.        ,\n",
      "       0.        , 0.08333333, 0.07407407, 0.0625    , 0.        ,\n",
      "       0.        , 0.        , 0.1       , 0.        , 0.10714286,\n",
      "       0.        , 0.03703704, 0.        , 0.03225806, 0.        ,\n",
      "       0.02222222, 0.05128205, 0.        , 0.        , 0.        ,\n",
      "       0.01724138, 0.21052632, 0.        , 0.15384615, 0.        ,\n",
      "       0.08571429, 0.14285714, 0.5       , 0.17391304, 0.2       ,\n",
      "       0.        , 0.015625  , 0.        , 0.33333333, 0.        ,\n",
      "       0.0952381 , 0.        , 0.        , 0.0625    , 0.        ,\n",
      "       0.        , 0.16666667, 0.03333333, 0.        , 0.33333333,\n",
      "       0.04761905, 0.        , 0.11111111, 0.        , 0.        ,\n",
      "       0.10526316, 0.01639344, 0.        , 0.01388889, 0.        ,\n",
      "       0.        , 0.        , 0.16666667, 0.11111111, 0.125     ,\n",
      "       0.05555556, 0.        , 0.02739726, 0.16666667, 0.        ,\n",
      "       0.07142857, 0.16666667, 0.04545455, 0.125     , 0.5       ,\n",
      "       0.11111111, 0.        , 0.        , 0.        , 0.1       ,\n",
      "       0.        , 0.        , 0.02857143, 0.075     , 0.125     ,\n",
      "       0.06451613, 0.        , 0.16666667, 0.28571429, 0.11111111,\n",
      "       0.        , 0.        , 0.2       , 0.25      , 0.33333333,\n",
      "       0.        , 0.08333333, 0.01754386, 0.125     , 0.04166667,\n",
      "       0.16666667, 0.        , 0.25      , 0.11111111, 0.03225806,\n",
      "       0.        , 0.        , 0.04918033, 0.        , 0.        ,\n",
      "       0.25      , 0.21428571, 0.        , 0.04615385, 0.        ,\n",
      "       0.07692308, 0.04444444, 0.5       , 0.        , 0.        ,\n",
      "       0.25      , 0.25      , 0.        , 0.18181818, 0.        ,\n",
      "       0.2       , 0.28571429, 0.        , 0.28571429, 0.        ,\n",
      "       0.16666667, 0.        , 0.02564103, 0.2       , 0.06666667,\n",
      "       0.04347826, 0.5       , 0.        , 0.11111111, 0.08      ,\n",
      "       0.        , 0.16666667, 0.05263158, 0.28571429, 0.05555556,\n",
      "       0.25      , 0.18181818, 0.09090909, 0.        , 0.025     ,\n",
      "       0.4       , 0.        , 0.02631579, 0.25      , 0.25      ,\n",
      "       0.02702703, 0.03448276, 0.02777778, 0.25      , 0.2       ,\n",
      "       0.02083333, 0.        , 0.25      , 0.1       , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.09090909, 0.11111111, 0.        , 0.        ,\n",
      "       0.14285714, 0.        , 0.02941176, 0.        , 0.        ,\n",
      "       0.11111111, 0.14285714, 0.        , 0.        , 0.04761905,\n",
      "       0.25      , 0.        , 0.04      , 0.        , 0.02702703,\n",
      "       0.03703704, 0.10344828, 0.0483871 , 0.16666667, 0.        ,\n",
      "       0.01818182, 0.02941176, 0.2       , 0.03636364, 0.03571429,\n",
      "       0.07692308, 0.05084746, 0.18181818, 0.06382979, 0.        ,\n",
      "       0.03174603, 0.02702703, 0.25      , 0.125     , 0.        ,\n",
      "       0.06666667, 0.        , 0.06666667, 0.        , 0.25      ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.1       ,\n",
      "       0.05882353, 0.1       , 0.        , 0.        , 0.2       ,\n",
      "       0.01694915, 0.16666667, 0.        , 0.1       , 0.33333333,\n",
      "       0.05263158, 0.04545455, 0.11111111, 0.07692308, 0.25      ,\n",
      "       0.        , 0.        , 0.16666667, 0.        , 0.125     ,\n",
      "       0.07692308, 0.0862069 , 0.05      , 0.        , 0.2       ,\n",
      "       0.03571429, 0.15384615, 0.16666667, 0.        , 0.0625    ,\n",
      "       0.33333333, 0.2       , 0.03030303]))\n"
     ]
    }
   ],
   "source": [
    "print(\"The precision recall score is : \" + str( prs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNNet representation sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating synthetic interactions dataset\n",
    "\n",
    "from spotlight.datasets.synthetic import generate_sequential\n",
    "\n",
    "synthetic_dataset = generate_sequential(num_users=100,\n",
    "                              num_items=1000,\n",
    "                              num_interactions=10000,\n",
    "                              concentration_parameter=0.01,\n",
    "                              order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "\n",
    "train_3, test_3 = user_based_train_test_split(synthetic_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into sequence representations\n",
    "\n",
    "train_3 = train_3.to_sequence()\n",
    "test_3 = test_3.to_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "\n",
    "model_implicit_sequence = ImplicitSequenceModel(n_iter=10,\n",
    "                              representation='cnn',\n",
    "                              loss='bpr',\n",
    "                              embedding_dim=32,\n",
    "                              batch_size=256,\n",
    "                              l2=0.0, \n",
    "                              learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.4997377023100853\n",
      "Epoch 1: loss 0.4939677119255066\n",
      "Epoch 2: loss 0.4866984486579895\n",
      "Epoch 3: loss 0.4726169556379318\n",
      "Epoch 4: loss 0.45454241335392\n",
      "Epoch 5: loss 0.4323286861181259\n",
      "Epoch 6: loss 0.40687383711338043\n",
      "Epoch 7: loss 0.39838360249996185\n",
      "Epoch 8: loss 0.38531702756881714\n",
      "Epoch 9: loss 0.3658946305513382\n"
     ]
    }
   ],
   "source": [
    "model_implicit_sequence.fit(train_3, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "mrr_sequence = sequence_mrr_score(model_implicit_sequence, test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00148368, 0.00228311, 0.00934579, 0.00632911, 0.00540541,\n",
       "       0.00104058, 0.01052632, 0.00111359, 0.00136986, 0.0014881 ,\n",
       "       0.00109649, 0.00190476, 0.05263158, 0.00355872, 0.00117096,\n",
       "       0.03225806, 0.01470588, 0.00151976, 0.0010142 , 0.0015083 ,\n",
       "       0.01265823, 0.00104603, 0.00146628, 0.00149477, 0.00121359,\n",
       "       0.003663  , 0.05263158, 0.00123762, 0.00296736, 0.00144092,\n",
       "       0.0010395 , 0.01351351, 0.002331  , 0.00826446, 0.00206186,\n",
       "       0.0022779 , 0.5       , 0.00185529, 0.00112613, 0.00367647,\n",
       "       0.00126103, 0.00124844, 0.02777778, 0.02439024, 0.00135135,\n",
       "       0.00309598, 0.00166667, 0.0013369 , 0.00431034, 0.00125156,\n",
       "       0.00263158, 0.00221239, 0.00304878, 0.00307692, 0.00546448,\n",
       "       0.00151745, 0.06666667, 0.00287356, 0.01111111, 0.00719424,\n",
       "       0.00806452, 0.00124378, 0.00452489, 0.01639344, 0.0078125 ,\n",
       "       0.00564972, 0.00298507, 0.00145349, 0.00115207, 0.002079  ,\n",
       "       0.00408163, 0.00440529, 0.0019685 , 0.00185529, 0.00110742,\n",
       "       0.00158983, 0.01098901, 0.00198807, 0.00228311, 0.02173913,\n",
       "       0.0010582 , 0.01098901, 0.00286533, 0.00268097, 0.00103734,\n",
       "       0.00403226, 0.00130378, 0.00110988, 0.00184843, 0.00127714,\n",
       "       0.00342466, 0.00104712, 0.00145138, 0.00122549, 0.00133156,\n",
       "       0.0037037 , 0.0027027 , 0.00182149, 0.0021322 , 0.00102459,\n",
       "       0.00130719, 0.00131062, 0.00429185, 0.00289017, 0.00226244,\n",
       "       0.00384615, 0.00159744, 0.00363636, 0.00395257, 0.01020408,\n",
       "       0.0012285 , 0.00127065, 0.0033557 , 0.00189394, 0.00444444,\n",
       "       0.00324675, 0.00139276, 0.00110497, 0.00128535, 0.00148368,\n",
       "       0.00128866, 0.0011655 , 0.00240385, 0.00173913, 0.04545455,\n",
       "       0.00156006, 0.00359712, 0.00438596, 0.01923077, 0.00142653,\n",
       "       0.00144928, 0.00444444, 0.00510204, 0.00246914, 0.00127065,\n",
       "       0.00138122, 0.00373134, 0.00229885, 0.00129199, 0.07142857,\n",
       "       0.00166389, 0.00909091, 0.00308642, 0.00115607, 0.00775194,\n",
       "       0.00143266, 0.00480769, 0.0010989 , 0.00102041, 0.00133333,\n",
       "       0.00120919, 0.00128205, 0.00371747, 0.00243309, 0.00502513,\n",
       "       0.0041841 , 0.00101523, 0.00526316, 0.0013459 , 0.00183486,\n",
       "       0.02631579, 0.00487805, 0.00117647, 0.00288184, 0.00168919,\n",
       "       0.0014245 , 0.00102881, 0.00132979, 0.00129534, 0.00518135,\n",
       "       0.00113636, 0.00108108, 0.00374532, 0.03846154, 0.00239234,\n",
       "       0.01818182, 0.00322581, 0.00636943, 0.00353357, 0.00151515,\n",
       "       0.00137741, 0.00139665, 0.05555556, 0.00154321, 0.00505051,\n",
       "       0.00149701])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model on MovieLens dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train_4, test_4 = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.representations import CNNNet\n",
    "\n",
    "cnn_net = CNNNet(train_4.num_items,\n",
    "             embedding_dim=128,\n",
    "             kernel_width=5,\n",
    "             dilation=2,\n",
    "             num_layers=5,\n",
    "             nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "\n",
    "model_4 = ImplicitSequenceModel(loss='bpr',\n",
    "                              representation=cnn_net,\n",
    "                              batch_size=256,\n",
    "                              learning_rate=0.01,\n",
    "                              l2=0.0,\n",
    "                              n_iter=10,\n",
    "                              use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.2707342929912336\n",
      "Epoch 1: loss 0.2598790955362898\n",
      "Epoch 2: loss 0.26290226208441186\n",
      "Epoch 3: loss 0.2626385928103418\n",
      "Epoch 4: loss 0.2602262077006427\n",
      "Epoch 5: loss 0.26640368727120484\n",
      "Epoch 6: loss 0.2642526233738119\n",
      "Epoch 7: loss 0.264411213723096\n",
      "Epoch 8: loss 0.26808473467826843\n",
      "Epoch 9: loss 0.27185893555482227\n"
     ]
    }
   ],
   "source": [
    "model_4.fit(train_4.to_sequence(), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "test_mrr = sequence_mrr_score(model_4, test_4.to_sequence())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test mrr is : [0.0007722  0.00127714 0.00066007 ... 0.01587302 0.025      0.5       ]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Test mrr is : \" + str(test_mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMNet representation Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train_5, test_5 = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "\n",
    "model_5 = ImplicitSequenceModel(loss='bpr',\n",
    "                                  representation='lstm',\n",
    "                                  batch_size=256,\n",
    "                                  learning_rate=0.01,\n",
    "                                  l2=0.0,\n",
    "                                  n_iter=10,\n",
    "                                  use_cuda=torch.cuda.is_available()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.2957745907884656\n",
      "Epoch 1: loss 0.20644947118831403\n",
      "Epoch 2: loss 0.20198661088943481\n",
      "Epoch 3: loss 0.19775428148833188\n",
      "Epoch 4: loss 0.19755354704278888\n",
      "Epoch 5: loss 0.19572606998862643\n",
      "Epoch 6: loss 0.19390447889313553\n",
      "Epoch 7: loss 0.1961326924237338\n",
      "Epoch 8: loss 0.19201841860106497\n",
      "Epoch 9: loss 0.19421355561776596\n"
     ]
    }
   ],
   "source": [
    "model_5.fit(train_5.to_sequence(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "test_mrr_lstm_representaion = sequence_mrr_score(model_5, test_5.to_sequence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LSTM representation mrr is : [0.00076161 0.00101729 0.0019084  ... 0.00980392 0.01351351 0.01136364]\n"
     ]
    }
   ],
   "source": [
    "print(\"The LSTM representation mrr is : \" + str(test_mrr_lstm_representaion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling representation Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train_6, test_6 = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "\n",
    "model_6 = ImplicitSequenceModel(loss='bpr',\n",
    "                                  representation='pooling',\n",
    "                                  batch_size=256,\n",
    "                                  learning_rate=0.01,\n",
    "                                  l2=0.0,\n",
    "                                  n_iter=10,\n",
    "                                  use_cuda=torch.cuda.is_available()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.42880066235860187\n",
      "Epoch 1: loss 0.22821564204765088\n",
      "Epoch 2: loss 0.17431367256424643\n",
      "Epoch 3: loss 0.15865221348675815\n",
      "Epoch 4: loss 0.14969184904387503\n",
      "Epoch 5: loss 0.14296503590814996\n",
      "Epoch 6: loss 0.13879458561088098\n",
      "Epoch 7: loss 0.13592730643171252\n",
      "Epoch 8: loss 0.1320925969066042\n",
      "Epoch 9: loss 0.13007174229080026\n"
     ]
    }
   ],
   "source": [
    "model_6.fit(train_6.to_sequence(), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "test_mrr_pooling_representation = sequence_mrr_score(model_6, test_6.to_sequence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pooling representation mrr is : [0.00083542 0.00537634 0.0027027  ... 0.01639344 0.00311526 0.03448276]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Pooling representation mrr is : \" + str(test_mrr_pooling_representation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
